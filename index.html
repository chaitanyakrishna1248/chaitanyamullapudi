<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Resume - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Chaitanya Krishna Mullapudi</span>
                <span class="d-none d-lg-block"><img class="profile-pic" src="assets/img/profile.jpeg" alt="" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Chaitanya Krishna <span class="text-primary">Mullapudi</span>
                    </h1>
                    <div class = "subheading "> Machine Learning Enthusiast</div> 
                    <div class="subheading mb-5">
                        Seattle, WA · (206) 387-9632 ·
                        <a class = "text-secondary" href="mailto:name@email.com">chaitanya.krishna1002@gmail.com</a>
                    </div>
                    <p class="lead mb-5">I am a dynamic and results-oriented Machine Learning enthusiast with a proven track record of academic excellence and practical expertise. Currently pursuing an M.S. in Electrical and Computer Engineering at the University of Washington (UW), specializing in Machine Learning, I hold a strong GPA of 3.92/4.0. 
                        <br><br>
                    I find myself deeply fascinated by the world of AI and its profound influence on our daily lives. I was particularly intrigued by the mathematics of neural networks during a course on deep learning. I came to understand how remarkably these networks learn intricate patterns from complex data. I don't see neural networks as a black box rather as a meticulously designed set of mathematical operations tailored to capture even the most intricate patterns. This perspective fuels my motivation to contribute to the development of better AI models, with the ultimate aim of making the world a safer place.
                    <br><br>
                    I am currently seeking full-time opportunities as a Machine Learning/Deep Learning Engineer where I can apply and further develop my skills. If you have open positions and believe that my expertise aligns with your team's needs, please feel free to reach out. I am easily accessible via email or LinkedIn. Here is the <a href = "https://drive.google.com/file/d/1KOO_-w3LorSbOYQigBdh_-kN_lroW0ws/view?usp=sharing"><b>link</b></a> to my resume.

                    </p>
                    
                        <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/ckm26/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/chaitanyakrishna1248"><i class="fab fa-github"></i></a>
                        <a class="social-iconn" href="https://scholar.google.com/citations?user=fP0U7sUAAAAJ&hl=en&authuser=1">
                            <img src="assets\img\scholar.png" alt="Google Scholar Profile" class = "social-iconn img">
                        </a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />

            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">University of Washington</h3>
                            <div class="subheading mb-3">Master of Science</div>
                            <div>Computer Engineering - Machine Learning Track</div>
                            <p>GPA: 3.92 / 4.0</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2022 -  Present</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Vellore Institute of Technology</h3>
                            <div class="subheading mb-3">Bachelor of Technology</div>
                            <div>Electronics and Communication Engineering - IoT and Sensors Track</div>
                            <p>GPA: 3.7 / 4.0</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2018 - August 2022</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />

            <!-- Experience-->
            <section class="resume-section" id="experience">
                <div class="resume-section-content">
                    <h2 class="mb-5">Experience</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Deep Learning Co-Op</h3>
                            <div class="subheading mb-3">Torc Robotics, Austin</div>
                            <ul>
                                <li>Orchestrating close collaboration with engineering groups to spearhead the development of pioneering computer vision techniques, including
                                segmentation and depth estimation models, on <b><a>AWS EC2</a></b> instances, while harnessing the power of Docker for seamless deployment.</li>
                                <li>Applying advanced feature engineering techniques using python's <b>Numpy</b> library to transform large-scale datasets into a format optimized for
                                the model, ensuring enhanced compatibility and performance.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2023 - Present</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Graduate Research Assistant</h3>
                            <div class="subheading mb-3">SMARTS Lab, UW, Seattle</div>
                            <ul>
                                <li>Pioneered a dynamic pipeline on a robot using ROS, C++, Python for active object recognition in cluttered environments, seamlessly
                                    integrating a learning-based approach (TOPS) with a novel controller analogous to a PID controller to capture the next best view of a scene.</li>
                                <li>Elevated precision and robustness by introducing Mobile-SAM, an alternative segmentation model to ground-truth segmentation maps
                                    required for TOPS, fortifying the efficacy of the pipeline in a python environment.</li>
                                <li>Engineered a paradigm shift by adopting TensorRT format for both Mobile-SAM (encoder and decoder) and TOPS, drastically reducing
                                    inference time from 5 seconds to an impressive sub-1-second execution.</li>
                                <li>Demonstrated equivalency in accuracy between Mobile-SAM generated segmentation masks and ground-truth counterparts, validating the
                                    object segmentation model's robustness using. Achieved a striking sub-100ms total inference time for singular object recognition pipeline.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2023 - September 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Graduate Student Researcher</h3>
                            <div class="subheading mb-3">Robotics and State Estimation Lab, UW, Seattle</div>
                            <ul>
                                <li>Developed a unique data generation technique incorporating multiview images of Google scanned objects dataset and combined with the open
                                    source Megapose dataset to train on a novel transformer based 2D Unseen Object Segmentation model, recently accepted at CoRL 2023.</li>
                                <li>Achieved a remarkable 13% increase in mAP on YCB Multiview test dataset surpassing baseline results reported using DINOv2.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">July 2023 - September 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Graduate Student Researcher</h3>
                            <div class="subheading mb-3">Information Processing Lab, UW, Seattle</div>
                            <ul>
                                <li>Contributed to the research by training YOLOv7 architecture using PyTorch, OpenMMLab on synthetic data for multi-camera multiple
                                    people tracking as part of CVPR AI city challenge 2023.</li>
                                <li>Improved detecting and tracking accuracy without relying on camera parameters and achieved an impressive IDF1 score of 95.36% thereby
                                    securing first place in the challenge.</li>
                                <li>Improved mAP of HRNet by 10% over baseline on using YOLOv8 as object detector on synthetic data for Accessibility Vision and Autonomy
                                    Challenge on 2D human pose estimation.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">January 2023 - June 2023</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />

            <!--Publications-->
            <section class="resume-section" id="publications">
            <div class="resume-section-content">
                <h2 class="mb-5">Publications</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                  <img class = "publication-pic" border="0" alt="W3Schools" src="assets/img/paper1.png" > &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <div class="flex-grow-1">
                        <h3 class="mb-0">	Enhancing Multi-Camera People Tracking with Anchor-Guided Clustering and Spatio-Temporal Consistency ID Re-Assignment </h3>
                        <div class="subheading mb-0"> 2022 &nbsp;&nbsp; <!--[<a href="assets/cupl.pdf"> updated pdf </a>]--> &nbsp;&nbsp; [<a class = "text-secondary" href="https://arxiv.org/abs/2304.09471"> arxiv </a>] &nbsp;&nbsp; [<a class = "text-secondary" href="https://github.com/ipl-uw/AIC23_Track1_UWIPL_ETRI"> code </a>]</div>
                        <p> Multi-camera multiple people tracking has become an increasingly important area of research due to the growing demand for accurate and efficient indoor people tracking systems, particularly in settings such as retail, healthcare centers, and transit hubs. We proposed a novel multi-camera multiple people tracking method that uses anchor-guided clustering for cross-camera re-identification and spatio-temporal consistency for geometry-based cross-camera ID reassigning. Our approach aims to improve the accuracy of tracking by identifying key features that are unique to every individual and utilizing the overlap of views between cameras to predict accurate trajectories without needing the actual camera parameters. The method has demonstrated robustness and effectiveness in handling both synthetic and real-world data. The proposed method is evaluated on CVPR AI City Challenge 2023 dataset, achieving IDF1 of 95.36% with the first-place ranking in the challenge. </p>
                    </div>
                </div>

                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <img class = "publication-pic" border="0" alt="W3Schools" src="assets/img/paper2.png"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                      <div class="flex-grow-1">
                          <h3 class="mb-0">	Image Steganography Using GANs </h3>
                          <div class="subheading mb-0"> 2021 &nbsp;&nbsp; <!--[<a href="assets/cupl.pdf"> updated pdf </a>]--> &nbsp;&nbsp; [<a class = "text-secondary" href="https://link.springer.com/chapter/10.1007/978-3-030-79474-3_12"> link </a>] &nbsp;&nbsp;</div>
                          <p> To enhance confidential communication, this paper introduces a steganography system that hides information in images using Generative Adversarial Networks (GANs), which is more secure against intelligent detection systems compared to traditional methods. It utilizes an Extractor model to recover the embedded data with a high accuracy rate of 92.34%. The system also achieves a steganography capacity of 93.75e−3 bytes/pixel, suggesting improved security and data density. The proposed method significantly lowers the risk of data interception and unauthorized access by advanced intelligent systems, representing a forward step in secure network communications.</p>
                      </div>
                  </div>
                
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <img class = "pub-pic" alt="W3Schools" src="assets/img/paper3.png"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Autonomous Space Debris Collision Avoidance System </h3>
                        <div class="subheading mb-0"> 2021 &nbsp;&nbsp; <!--[<a href="assets/cupl.pdf"> updated pdf </a>]--> &nbsp;&nbsp; [<a class = "text-secondary" href="https://link.springer.com/chapter/10.1007/978-981-15-8221-9_232"> link </a>] &nbsp;&nbsp;</div>
                        <p> A major contributor to the setback of space exploration is the risk of space debris and their collisions with satellites. This paper will cover the methods proposed to produce a space collision avoidance system to automatically maneuver a satellite in a trajectory of collision and to deorbit a satellite safely when it is about to run out of fuel. The space collision avoidance system propounded predicts the path of debris and active satellites by a trained machine learning algorithm. Using the data obtained, it predicts the probability of impact between objects using a collision prediction algorithm developed. Upon reaching a specific threshold value, this would trigger the maneuvering of the satellite into a safe path away from the approaching debris, thus resolving the concerns regarding the deorbiting of dying satellites in low earth orbits, and satellite collisions. </p>
                    </div>
                </div>
            </div>
        </section>
        <hr class="m-0" />

            <!-- Personal Projects-->
            <section class="resume-section" id="projects">
                <div class="resume-section-content">
                    <h2 class="mb-5">Personal Projects</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Neural Network Visualization in DQN for Atari Games</h3>
                            <div class="subheading mb-3">Python, PyTorch, Google Colab</div>
                            <ul>
                                <li>Analyzed decision-making process of neural networks in DQN using PyTorch and enhanced interpretability by employing neuron and network
                                    dissection, Smooth Grad and Smooth GradCAM++ enabling gradient-based visualizations for Pong and Breakout Atari games.</li>
                                <li>Achieved a remarkable 20% and 8% improvement in the DQN agent's score for Pong and Breakout games by leveraging insights gained from
                                    the comprehensive analysis of these visualizations.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2023 - June 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Depth Estimation using GANs</h3>
                            <div class="subheading mb-3">Python, Tensorflow, Keras, Google Colab</div>
                            <ul>
                                <li>Conducted an in-depth examination of methodologies for improving monocular depth estimation for indoor RGB images using Tensorflow
                                    framework and Keras library, evaluating the performances of CNNs and GANs using established metrics.</li>
                                <li> Accomplished a remarkable reduction in root mean square (RMS) error, with fine-tuning Conditional GANs achieving an impressive RMS
                                    score of 0.1536, surpassing prior methodologies.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">January 2022 - July 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Coursework Projects</h3>
                            <div class="subheading mb-3">Python, PyTorch, Google Colab</div>
                            <ul>
                                <li>Executed advanced estimation techniques including Kalman Filter, Extended Kalman Filter (EKF), and Particle Filter within
                                    the dynamic soccer field robot environment.</li>
                                <li>Conducted comprehensive simulations to evaluate the performance of motion planning methodologies such as A*, RRT, and
                                    RRT* on both 2DOF planar robot and car environments.</li>
                                <li>Implemented cutting-edge learning algorithms, including behavior cloning, DAgger, and Policy Gradient, within the Reacher
                                    environment, pushing the boundaries of autonomous decision-making and control.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">January 2022 - July 2023</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />

            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="subheading mb-3">Programming Languages & Tools</div>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-circle"></i></span>
                            <b>Programming Languages: </b>Python, C++, Embedded C, C, R, MATLAB
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-circle"></i></span>
                            <b>Data Manipulation & Analysis: </b>Pandas, Numpy, SQLite, SQL, Azure SQL 
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-circle"></i></span>
                            <b>Model Development & Evaluation:</b> Scikit learn, TensorFlow, PyTorch, Keras, OpenCV, OpenMMLab, TensorRT, ONNX, CUDA
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-circle"></i></span>
                            <b>Data Visualization: </b>Matplotlib, Seaborn, Tableau
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-circle"></i></span>
                            <b>Software Development / Project Management tools:</b> Linux, ROS, Git, Jira, AWS EC2, AWS S3, Docker, Jenkins
                        </li>
                    </ul>
                    <br>
                    <div class="subheading mb-3">Workflow</div>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Time Management and Task Prioritization
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Cross Functional Teams
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Agile Development & Scrum
                        </li>
                    </ul>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="interests">
                <div class="resume-section-content">
                    <h2 class="mb-5">Interests</h2>
                    <p>I'm not just a deep learning enthusiast clocking in hours; I'm also a bit of a scholarly adventurer, diving into the latest papers on generative AI, foundational models in vision,  segmentation, and depth estimation. Engaging in technical discussions about deep learning architectures isn't just a hobby, it's my calling. Plus, I've got a 'Thought of the Day' corner designed to spark conversations and collaborative musings among peers and fellow enthusiasts!</p>
                    <p class="mb-0">But wait—there's more to me than just nerdy things. I'm a fervent admirer of nature's craftings. Give me a trail to hike, a river to kayak, or a tennis match under the sun, and I'm there, recharging my soul. </p>
                    <br>
                    <p class = "mb-0">When forced indoors, I follow a number of sci-fi and fantasy genre movies, I am an aspiring chef (just kidding), and the best moments are those shared with friends. Ultimately, it's the laughter, the debates, the shared wonder—that truly make my day complete.</p>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Awards-->
            <section class="resume-section" id="awards">
                <div class="resume-section-content">
                    <h2 class="mb-5">Awards & Certifications</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Convolutional Neural Networks in TensorFlow
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Robotics powered by ROS
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Merit Scholarship - Among top 10 students in ECE (2019-20)
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Merit Scholarship - Among top 10 students in ECE (2018-19) 
                            
                        </li>

                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Selected for Top 10 Papers in Springer Journal's Special Edition for groundbreaking research on 'Image Steganography Using GANs'
                        </li>
                    </ul>
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
